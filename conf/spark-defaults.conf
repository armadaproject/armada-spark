spark.jars.ivy /tmp/.ivy
spark.armada.pod.labels foo=bar
spark.armada.lookouturl http://localhost:30000
spark.armada.queue test
#spark.executor.instances 3
#spark.armada.scheduling.nodeUniformity armada-spark
#spark.armada.scheduling.nodeSelectors armada-spark=true
#spark.armada.driver.limit.cores 200m
#spark.armada.driver.limit.memory 450Mi
#spark.armada.driver.request.cores 200m
#spark.armada.driver.request.memory 450Mi
#spark.armada.executor.limit.cores 100m
#spark.armada.executor.limit.memory 510Mi
#spark.armada.executor.request.cores 100m
#spark.armada.executor.request.memory 510Mi


# example s3/history server config:
#spark.hadoop.fs.s3a.path.style.access True
#spark.hadoop.fs.s3a.endpoint https://xx.com
#spark.eventLog.enabled true
#spark.eventLog.dir s3a://bucket/xx99
#spark.history.fs.logDirectory s3a://bucket/xx99
#spark.kubernetes.driver.secretKeyRef.AWS_SECRET_KEY=key1:secret_key
#spark.kubernetes.executor.secretKeyRef.AWS_SECRET_KEY=key1:secret_key
#spark.kubernetes.driver.secretKeyRef.AWS_ACCESS_KEY_ID=key1:access_key
#spark.kubernetes.executor.secretKeyRef.AWS_ACCESS_KEY_ID=key1:access_key



spark.hadoop.fs.s3a.access.key minioadmin
spark.hadoop.fs.s3a.secret.key minioadmin
spark.hadoop.fs.s3a.connection.ssl.enabled false
spark.kubernetes.executor.pod.featureSteps=org.apache.spark.deploy.k8s.features.ShuffleServiceExecutorFeatureStep
spark.blockManager.port=7337

## Fallback storage migration
spark.decommission.enabled=true
spark.storage.decommission.enabled=true
spark.storage.decommission.shuffleBlocks.enabled=true
spark.storage.decommission.shuffleBlocks.maxDiskSize=0
spark.storage.decommission.replicationReattemptInterval=100ms
spark.storage.decommission.fallbackStorage.cleanUp=true
spark.storage.decommission.fallbackStorage.replicationDelay=30s
spark.storage.decommission.fallbackStorage.replicationWait=1s
spark.armada.executor.trackerTimeout=36000s
spark.storage.decommission.fallbackStorage.path=s3a://test-bucket/shuffle/

## Shuffle tracking (required for fallback storage)
#spark.dynamicAllocation.shuffleTracking.enabled=true
#spark.dynamicAllocation.shuffleTracking.timeout=3600s
#spark.shuffle.service.enabled=true
#spark.shuffle.service.db.enabled=true

spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.committer.name=file
spark.hadoop.fs.s3a.multipart.threshold=320M
spark.hadoop.fs.s3a.multipart.size=32M
spark.hadoop.fs.s3a.connection.maximum=10000
spark.hadoop.fs.s3a.threads.max=5000


spark.hadoop.fs.s3a.endpoint http://minio:9000

spark.armada.driver.limit.memory 2Gi
spark.armada.driver.request.memory 2Gi
spark.armada.executor.limit.memory 2Gi
spark.armada.executor.request.memory 2Gi

spark.eventLog.enabled true
spark.eventLog.dir s3a://test-bucket/eventLog2
spark.history.fs.logDirectory /opt/spark/conf/eventLog2

## Debug logging for shuffle operations
#spark.executor.extraJavaOptions=-Dlog4j.configurationFile=file:///opt/spark/conf/log4j2-executor.properties

