name: E2E
author: EnricoMi
description: Github Action to run end-to-end tests against a Spark and Scala version

inputs:
  spark_version:
    description: Spark version to build against, e.g. "3.5.5" or "4.1.0-SNAPSHOT"
    required: true
  scala_version:
    description: Scala version to build with, e.g. "2.13.8"
    required: true
  java_version:
    description: Java version to build with, e.g. "11"
    required: true

runs:
  using: composite
  steps:
  - name: Checkout
    uses: actions/checkout@v4
    with:
      path: armada-spark
  - name: Checkout
    uses: actions/checkout@v4
    with:
      repository: armadaproject/armada-operator
      path: armada-operator

  - name: Restore Maven packages cache
    uses: actions/cache@v4
    with:
      path: ~/.m2/repository
      key: ${{ runner.os }}-mvn-e2e-${{ inputs.spark_version }}-${{ inputs.scala_version }}-${{ hashFiles('armada-spark/pom.xml') }}
      restore-keys:
        ${{ runner.os }}-mvn-e2e-${{ inputs.spark_version }}-${{ inputs.scala_version }}-${{ hashFiles('armada-spark/pom.xml') }}
        ${{ runner.os }}-mvn-e2e-${{ inputs.spark_version }}-${{ inputs.scala_version }}-
  - name: Setup JDK
    uses: actions/setup-java@v4
    with:
      java-version: ${{ inputs.java_version }}
      distribution: 'zulu'
  - name: Setup Go
    id: setup-go
    uses: ./armada-operator/.github/actions/setup-go-cache
    with:
      cache-prefix: go-e2e

  - name: Set Spark and Scala versions
    working-directory: armada-spark
    run: |
      # Set Spark and Scala versions
      ./scripts/set-version.sh "${{ inputs.spark_version }}" "${{ inputs.scala_version }}"
      echo "::group::changes"
      git diff
      echo "::endgroup::"
    shell: bash
  - name: Fetch mvn dependencies
    continue-on-error: true
    working-directory: armada-spark
    run: |
      # Fetch mvn dependencies
      echo "::group::mvn go-offline"
      mvn --batch-mode --update-snapshots dependency:go-offline
      echo "::endgroup::"
    shell: bash
  - name: Build package
    working-directory: armada-spark
    run: |
      # Build package
      echo "::group::mvn package"
      mvn --batch-mode package
      echo "::endgroup::"
    shell: bash
  - name: Build image
    env:
      JAVA_VERSION: ${{ inputs.java_version }}
    run: |
      # Build image
      echo "::group::createImage.sh"
      ./armada-spark/scripts/createImage.sh
      echo "::endgroup::"
    shell: bash
  - name: Test job processing
    id: submit
    run: |
      ./armada-spark/scripts/dev-e2e.sh
    shell: bash
  # - name: Patch armada-operator to configure for spark-armada e2e tests
  #   run: |
  #     # Patch armada-operator
  #     patch -p1 -d ./armada-operator/ < ./armada-spark/e2e/armada-operator.patch
  #   shell: bash
  # - name: Start Armada Kind cluster
  #   id: kind
  #   working-directory: armada-operator
  #   run: |
  #     # Start Armada Kind cluster
  #     echo "::group::make kind-all"
  #     make kind-all
  #     echo "::endgroup::"

  #     echo "$PWD/bin/app/" >> "$GITHUB_PATH"
  #     echo "$PWD/bin/tooling/" >> "$GITHUB_PATH"
  #   shell: bash
  # - name: Create Armada queue
  #   run: |
  #     # Create Armada queue
  #     echo "::group::armadactl create queue test"
  #     until armadactl create queue test 2>&1
  #     do
  #       echo "::endgroup::"
  #       sleep 1
  #       echo "::group::armadactl create queue test"
  #     done
  #     echo "::endgroup::"

  #     sleep 60
  #   shell: bash
  # - name: Submit SparkPi
  #   id: submit
  #   run: |
  #     # Submit SparkPi
  #     echo "::group::submitSparkPi.sh"
  #     ./armada-spark/scripts/submitSparkPi.sh 2>&1 | tee submitSparkPi.log
  #     echo "::endgroup::"

  #     while read -r line; do
  #       if [[ "$line" == "Submitted driver job with ID:"* ]]; then
  #         # strip the leading text…
  #         jobid=${line#Submitted driver job with ID:\ }
  #         # …then cut off at the first comma
  #         jobid=${jobid%%,*}
  #         echo "jobid=$jobid" >> "$GITHUB_OUTPUT"
  #       fi
  #     done < submitSparkPi.log
      
  #     if [[ -z "$jobid" ]]; then
  #       echo "No job id detected"
  #       exit 1
  #     fi
  #   shell: bash
  # - name: Watch job
  #   run: |
  #     # Watch job
  #     sleep 10
  #     timeout 15m armadactl watch test armada-spark --exit-if-inactive 2>&1 | tee armadactl.watch.log

  #     if grep "Job failed:" armadactl.watch.log; then echo "Job failed"; exit 1; fi
  #   shell: bash
  - name: Ensure job completed
    run: |
      timeout 5m bash -c '
        while kubectl get pods -l spark-job=example \
              --field-selector=status.phase!=Succeeded,status.phase!=Failed \
              -o name | grep -q .; do
          echo "waiting…"; sleep 5;
        done
      '
      if [[ $? -eq 124 ]]; then
        echo "Timeout after 5m" >&2
        exit 1
      fi
      echo "All pods have terminated."
    shell: bash
  - name: Inspect k8s pods
    id: k8s-pods
    if: always() && steps.kind.outcome == 'success'
    run: |
      # Inspect k8s pods
      echo "::group::pods"
      kubectl get pods -A
      echo "::endgroup::"

      kubectl get pods -A | tail -n+2 | sed -E -e "s/ +/ /g" | cut -d " " -f 1-2 | while read namespace pod
      do
        echo "::group::$pod"
        kubectl get pod "$pod" --namespace "$namespace" --output json 2>&1 | tee "$namespace.$pod.json"
        kubectl logs "$pod" --namespace "$namespace" 2>&1 | tee "$namespace.$pod.log"
        echo "::endgroup::"
      done
    shell: bash
  - name: Inspect Lookout
    if: always() && steps.submit.outcome == 'success'
    run: |
      # Inspect k8s pods
      echo "::group::Inspect k8s pods"
      curl --silent --show-error -X POST "http://localhost:30000/api/v1/jobSpec" --json '{"jobId":"${{ steps.submit.outputs.jobid }}"}' | jq
      echo "::endgroup::"
    shell: bash
  - name: Confirm number of executors
    if: always()
    run: |
      # Confirm number of executors
      echo "::group::Confirm number of executors"
      expectedExecutorCount=`grep 'conf spark.executor.instances' ./armada-spark/scripts/submitSparkPi.sh | grep -oP 'spark\.executor\.instances=\K\d+'`
      actualExecutorCount=`grep "ArmadaDriverEndpoint: Registered executor" default.armada-${{ steps.submit.outputs.jobid }}-0.log | wc -l`
      echo executor count expected: $expectedExecutorCount actual: $actualExecutorCount
      if [ $expectedExecutorCount -eq $actualExecutorCount ]; then
        echo "got expected executor count"
      else
        echo "Bad executor count"; exit 1
      fi
      echo "::endgroup::"
    shell: bash
  - name: Confirm node selection
    if: always()
    run: |
      # Confirm node selection
      echo "::group::Confirm node selection"
      success=true
      expectedNode="armada-worker2"

      for pod in default.armada-*-0.json
      do
        echo "pod ${pod/%.json/}"
        nodeSelector=$(jq -r '.spec.nodeSelector."armada-spark"' "$pod")
        actualNode=$(jq -r .spec.nodeName "$pod")

        if [[ "$nodeSelector" == "true" ]]
        then
          echo "- Node selector exists"
        else
          echo "- Node selector is missing"
          success=false
        fi

        if [[ "$actualNode" == "$expectedNode" ]]
        then
          echo "- Pod assigned to expected node"
        else
          echo "- Pod assigned to unexpected node: $actualNode"
          success=false
        fi
        jq '.spec | { "nodeName": .nodeName, nodeSelector: .nodeSelector }' "$pod"
        echo
      done
      "$success"
      echo "::endgroup::"
    shell: bash
  - name: Upload k8s insights
    if: always()
    uses: actions/upload-artifact@v4
    with:
      name: k8s-${{ inputs.spark_version }}-${{ inputs.scala_version }}
      path: |
        *.log
        *.json
