name: E2E
author: EnricoMi
description: Github Action to run end-to-end tests against a Spark and Scala version

inputs:
  spark_version:
    description: Spark version to build against, e.g. "3.5.5" or "4.1.0-SNAPSHOT"
    required: true
  scala_version:
    description: Scala version to build with, e.g. "2.13.8"
    required: true
  java_version:
    description: Java version to build with, e.g. "11"
    required: true

runs:
  using: composite
  steps:
  - name: Checkout
    uses: actions/checkout@v4
    with:
      path: armada-spark

  - name: Restore Maven packages cache
    uses: actions/cache@v4
    with:
      path: ~/.m2/repository
      key: ${{ runner.os }}-mvn-e2e-${{ inputs.spark_version }}-${{ inputs.scala_version }}-${{ hashFiles('armada-spark/pom.xml') }}
      restore-keys:
        ${{ runner.os }}-mvn-e2e-${{ inputs.spark_version }}-${{ inputs.scala_version }}-${{ hashFiles('armada-spark/pom.xml') }}
        ${{ runner.os }}-mvn-e2e-${{ inputs.spark_version }}-${{ inputs.scala_version }}-
  - name: Setup JDK
    uses: actions/setup-java@v4
    with:
      java-version: ${{ inputs.java_version }}
      distribution: 'zulu'
  - name: Setup Go
    id: setup-go
    uses: armadaproject/armada-operator/.github/actions/setup-go-cache@main
    with:
      cache-prefix: go-e2e

  - name: Set Spark and Scala versions
    working-directory: armada-spark
    run: |
      # Set Spark and Scala versions
      ./scripts/set-version.sh "${{ inputs.spark_version }}" "${{ inputs.scala_version }}"
      echo "::group::changes"
      git diff
      echo "::endgroup::"
    shell: bash
  - name: Fetch mvn dependencies
    continue-on-error: true
    working-directory: armada-spark
    run: |
      # Fetch mvn dependencies
      echo "::group::mvn go-offline"
      mvn --batch-mode --update-snapshots dependency:go-offline
      echo "::endgroup::"
    shell: bash
  - name: Build package
    working-directory: armada-spark
    run: |
      # Build package
      echo "::group::mvn package"
      mvn --batch-mode package
      echo "::endgroup::"
    shell: bash
  - name: Build image
    env:
      JAVA_VERSION: ${{ inputs.java_version }}
    run: |
      # Build image
      echo "::group::createImage.sh"
      ./armada-spark/scripts/createImage.sh
      echo "::endgroup::"
    shell: bash
  - name: Test job processing
    id: submit
    run: |
      echo "::group::dev-e2e.sh"
      ./armada-spark/scripts/dev-e2e.sh
      echo "::endgroup::"
    shell: bash
  - name: Ensure job completed
    run: |
      timeout 5m bash -c '
        while kubectl get pods -l spark-job=example \
              --field-selector=status.phase!=Succeeded,status.phase!=Failed \
              -o name | grep -q .; do
          echo "waitingâ€¦"; sleep 5;
        done
      '
      if [[ $? -eq 124 ]]; then
        echo "Timeout after 5m" >&2
        exit 1
      fi
      echo "All pods have terminated."
    shell: bash
  - name: Inspect k8s pods
    id: k8s-pods
    if: always() && steps.kind.outcome == 'success'
    run: |
      # Inspect k8s pods
      echo "::group::pods"
      kubectl get pods -A
      echo "::endgroup::"

      kubectl get pods -A | tail -n+2 | sed -E -e "s/ +/ /g" | cut -d " " -f 1-2 | while read namespace pod
      do
        echo "::group::$pod"
        kubectl get pod "$pod" --namespace "$namespace" --output json 2>&1 | tee "$namespace.$pod.json"
        kubectl logs "$pod" --namespace "$namespace" 2>&1 | tee "$namespace.$pod.log"
        echo "::endgroup::"
      done
    shell: bash
  - name: Inspect Lookout
    if: always() && steps.submit.outcome == 'success'
    run: |
      # Inspect k8s pods
      echo "::group::Inspect k8s pods"
      curl --silent --show-error -X POST "http://localhost:30000/api/v1/jobSpec" --json '{"jobId":"${{ steps.submit.outputs.jobid }}"}' | jq
      echo "::endgroup::"
    shell: bash
  - name: Confirm number of executors
    if: always()
    run: |
      # Confirm number of executors
      echo "::group::Confirm number of executors"
      expectedExecutorCount=`grep 'conf spark.executor.instances' ./armada-spark/scripts/submitSparkPi.sh | grep -oP 'spark\.executor\.instances=\K\d+'`
      actualExecutorCount=`grep "ArmadaDriverEndpoint: Registered executor" default.armada-${{ steps.submit.outputs.jobid }}-0.log | wc -l`
      echo executor count expected: $expectedExecutorCount actual: $actualExecutorCount
      if [ $expectedExecutorCount -eq $actualExecutorCount ]; then
        echo "got expected executor count"
      else
        echo "Bad executor count"; exit 1
      fi
      echo "::endgroup::"
    shell: bash
  - name: Confirm node selection
    if: always()
    run: |
      # Confirm node selection
      echo "::group::Confirm node selection"
      success=true
      expectedNode="armada-worker2"

      for pod in default.armada-*-0.json
      do
        echo "pod ${pod/%.json/}"
        nodeSelector=$(jq -r '.spec.nodeSelector."armada-spark"' "$pod")
        actualNode=$(jq -r .spec.nodeName "$pod")

        if [[ "$nodeSelector" == "true" ]]
        then
          echo "- Node selector exists"
        else
          echo "- Node selector is missing"
          success=false
        fi

        if [[ "$actualNode" == "$expectedNode" ]]
        then
          echo "- Pod assigned to expected node"
        else
          echo "- Pod assigned to unexpected node: $actualNode"
          success=false
        fi
        jq '.spec | { "nodeName": .nodeName, nodeSelector: .nodeSelector }' "$pod"
        echo
      done
      "$success"
      echo "::endgroup::"
    shell: bash
  - name: Upload k8s insights
    if: always()
    uses: actions/upload-artifact@v4
    with:
      name: k8s-${{ inputs.spark_version }}-${{ inputs.scala_version }}
      path: |
        *.log
        *.json
